# 个人小玩具：协程爬虫介绍&去重判断

## 写在前面

首先要明白协程的含义：就是比线程更小的操作单位。底层工作由python和操作系统做了，理解为小一级线程和知道如何去用就好了。

先贴上对我理解相关概念帮助很大的几篇文章：

https://zhuanlan.zhihu.com/p/25228075

http://www.dongwm.com/archives/%E4%BD%BF%E7%94%A8Python%E8%BF%9B%E8%A1%8C%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B-asyncio%E7%AF%87/

http://aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html

## 正文

这次的爬虫框架的主体是由500lines的异步爬虫改过来的。

首先分析一下500lines的爬虫：

这个爬虫里面除了主爬虫逻辑，还包括了report，和单元测试模块，但暂时这里只分析主逻辑。

 

实现的功能：

将所有的爬取到的 url 放到python自带的set里面（自动去重），然后还有就是实现了限定主域名，储存方面都是运用了内存，没有持久化。

在生成请求方面，允许有限次的自动重拨操作，也限定了重定向次数

分析页面，就是用正则去爬取页面中符合规则的url，然后放到上面讲到的那个set里面

并发，也就是协程，用asynico.Task来生产一定数量的协程



根据这个爬虫框架，我仿写了一个小爬虫

URL处理方面：redis（主要是mysql不会用）

分析页面：lxml

最开始的想法是直接仿造主逻辑，只在最后爬取页面后增加保存图片这个步骤

去重的办法用了bloom filter



## Blood filter

这个算法可以说是我接触到的，真正意义上的高大上算法（主要因为我看不懂，看不懂的都觉得很高大上）。

个人理解：其去重原理是计算单个元素的hash值，然后转成二进制，存到数据库里；当来一个新元素时，又计算这个新元素的hash值，转成二进制，然后去比较对应位，如果不相等，则必然不存在，如果相等，则有极小的可能是误判。

```python
import math
from math import log, e
import redis
import hashlib
from hashlib import md5


class SimpleHash(object):  # 生成hash值，并转换成bytes
    def __init__(self, cap, seed):
        self.cap = cap
        self.seed = seed

    def hash(self, value):
        ret = 0
        for i in range(value.__len__()):
            ret += self.seed*ret + ord(value[i])  # ord是取ascii码
        return (self.cap-1) & ret  # 根据位宽去截，最终只会返回一个数


class MyBloomFilter(object):
    def __init__(self, host='localhost', port=6379, db=0, key=None, blocknum=1, bit_size=1 << 20):   # 具体的位宽和种子数可以根据实际去查表
        self.sever = redis.StrictRedis(host=host, port=port, db=db)
        self.bit_size = bit_size
        self.seeds = [3, 5, 7, 11, 13, 31, 67]  # 等于每一个元素都有7个1
        if key is None:
            self.key = 'test_key'
        else:
            self.key = key
        self.blockNum = blocknum
        self.hashFunc = []
        for seed in self.seeds:  # 提前生成好hash处理器
            self.hashFunc.append(SimpleHash(self.bit_size, seed))

    def is_contains(self, str_input, key=None):
        if not key:
            key = self.key
        if not str_input:
            return False
        m5 = md5()
        m5.update(bytes(str(str_input), encoding='utf-8'))
        str_input = m5.hexdigest()  # 会得到一个由16进制组成的，长度为32位字符串
        contain = True
        for f in self.hashFunc:
            loc = f.hash(str_input)
            contain = contain & self.sever.getbit(key, loc)  # 逐位去比较
            if not contain:  # 不存在的判断是可以提前结束的
                break
        return contain

    def insert(self, str_input, key=None):
        if not key:
            key = self.key
        m5 = md5()
        m5.update(bytes(str(str_input), encoding='utf-8'))
        str_input = m5.hexdigest()
        for f in self.hashFunc:
            loc = f.hash(str_input)
            self.sever.setbit(key, loc, 1)  # 将这一位置1

if __name__ == '__main__':
    import time
    r = redis.StrictRedis()
    bf = MyBloomFilter(bit_size=1 << 23, db=1)
    url = 'http://www.hanhande.com/manhua/op/26129.shtml'
    print(bf.is_contains(url, key='bf_seen_urls'))
    print(bf.is_contains(url, key='bf_done_urls'))
```

